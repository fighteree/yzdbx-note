**简介** : Redis是一个基于netty实现的高新能的缓存中间件
## redis使用场景汇总

	缓存
		穿透、击穿、雪崩
		双写一致、持久化
		淘汰策略、数据过期
	分布式锁
	计数器
	保存用户token
	消息队列
	延迟队列


- - -
### 缓存穿透

如下图: 
![[Pasted image 20240923151139.png]]
如果有人作恶，重复的查询一个并不存在的数据，这样会导致他的每次查询请求都是去db层查询，严重的话会导致db挂掉.

**解决思路:**
- 缓存空的数据，如果从db层没有查询到结果就在redis缓存一个空的值，这样下次查询的话就会命中缓存了。优点是简单容易实现。缺点消耗内存，还可能会导致数据不一致的情况发生，原因是如果这个id的数据如果真的有了，但是在缓存中的值还是空值,所以说最好要设置缓存的一个失效时间或者是定期的清理缓存。
- 使用[[布隆过滤器]]

--- 

### 缓存击穿

如下图:
![[Pasted image 20240923164023.png]]

原因: 一个热点key过期了，刚好在这个时间有大量的并发请求来查询这个热点key，那么就会全部的去查询数据库最后导致数据库宕机

解决思路:
- **互斥锁的方法:** 线程1在请求这个key时发现缓存过期时会上锁去查询数据库，然后将查询的结果写进缓存最后释放锁，这个时候如果线程2来查询这个key也是没有命中缓存更拿不到锁，这个时候线程2会不断的重试去缓存中拿数据，直到线程1完成了缓存的重建。缺点是会造成线程的阻塞，性能很低。**(强一致性)**
- **逻辑过期:** 在构建缓存时不设置过期时间，新添加一个过期时间的字段expire，每次命中缓存时会去根据这个过期时间和当前时间进行一个比较，如果时间逻辑过期了，就上锁，然后主线程直接返回过期的数据，同时开启一个新的线程去完成查db和更新缓存的动作。比起`互斥锁`的方式性能大大的提升，缺点是会造成数据短时间的不一致情况，对于哪些对数据一致性要求不是很离谱的项目来说实用。**(最终一致性)**

--- 

### 缓存雪崩

如下图:
![[Pasted image 20240923184948.png]]

原因: 大量的热点key在同一时间全部过期或redis宕机的情况导致请求全部到了db层，最终导致数据库宕机。

解决方法:
1. 给不同的key的过期时间添加一个随机值，这样就降低了缓存key在同一时间过期的问题
2. 使用redis的高可用， 哨兵、集群
3. 可以添加多级缓存，使用Guava或Caffeine等框架
4. 保底手段可以在接口做限流的处理

--- 


### 双写一致问题

问题： 如何保证数据库中的数据和缓存中的数据保持一致？

#### 延迟双删（最简单）

<mark style="background: #FFB8EBA6;">延迟双删：</mark>: 最容易实现的一种方式，不需要借助任何的中间件，纯JDK内库实现。
	实现思路：当一个线程需要对数据库修改时，先删除缓存，在修改数据库，为防止同一时刻
	由于mysql的事物隔离机制导致其他的线程拿到的还是旧数据且刚好需要做重写缓存的操作导致的脏数据，所以使用JDK的延迟任务线程去做一个异步的再次删除缓存的操作，延迟的时间可以根据业务的复杂度来定，一般的话1秒左右就ok了。这种方式只能尽量的减少脏数据，但是不能完成的避免脏数据。
	
#### 最终一致(对数据时效性要求不高)

 <mark style="background: #FFB8EBA6;">使用MQ：</mark>将写缓存的所有操作都有MQ的消费者去完成。
	实现思路: 不管是读还是写，只要是最后需要写缓存的话，就给MQ发一条消息，消息体可以是这条数据的ID ，然后消费者收到了消息后根据这个ID去数据库中查询数据，然后将查询到的数据写到缓存。由于MQ是具有可靠性的所以这个方案可以保证数据的最终一致性。

#### 数据强一致性

<mark style="background: #FFB8EBA6;">使用读写锁：</mark>Redisson提供一个获取读写锁的Api

- 共享锁(读锁) ,上锁后其他的线程对受保护的代码只有读权限，拿不到写锁。
- 排他锁(写锁), 上锁后其他的线程对受保护的代码既不能读也不能写，只能等待锁释放才能操作。

**实现思路** : 读的时候上读锁修改数据时上写锁，这样就可以解决数据不一致的情况，缺点是性能差



--- 



### Redis持久化

![[Pasted image 20241104161239.png]]
以上是通过redis命令手动的进行数据的持久化备份


redis自动做持久化操作:
```java
redis.conf配置文件中有如下的一段配置:

## 900秒内有一个key被修改redis会自动执行bgsave命令进行数据备份的操作
save 900 1
save 300 10
save 60 10000

```


#### RDB持久化原理

![[Pasted image 20241104170123.png]]

解释: `bgsave` 命令执行后redis会fork一个子进程来完成内存数据的持久化操作，所以主线程是不会去阻塞来的用户的请求命令的。



步骤：
	1. redis会复制一个子进程，最重要的是redis并没有复制缓存的数据而是将[页表](Redis持久化中的页表)复制给了子进程，所以创建进程的速度是非常快的，纳秒级。
	2. 子进程根据页表的虚拟内存读取到缓存的所有数据，生成新的RDB文件并替换旧的RDB文件


由于子进程在持久化的过程中主进程任然可以接受用户的写请求，此时持久化会导致脏数据的情况。所以redis使用了一种叫做copy-on-write的技术。主进程在持久化的过程中如果有写的操作会重新复制一个数据副本来存储，同时将页表的虚拟地址指向新开辟的内存，之前的页表只能读而不能直接写,这样就避免了脏数据的出现。



#### AOF持久化原理

![[Pasted image 20241104221515.png]]

>[!todo] 提示
>redis的AOF持久化模式默认是关闭的，需要手动的开启。

![[Pasted image 20241104223806.png]]

![[Pasted image 20241104224056.png]]


>[!note] 笔记
>由于AOF持久化是记录的所有的写命令，所以一般来说.aof的文件体积会越来越大。
>redis 有一个`bgrewriteaof`的命令可以对.aof文件进行重新，意思就是如果一个key记录了多次的写命令它会压缩成只保留最后一个写命令从而降低了文件的体积大小。
>同时redis.conf中可以设置文件超过了多少兆会自动的去执行这个命令，配置如下图

![[Pasted image 20241104225116.png]]



#### RDB比对AOF优缺点

![[Pasted image 20241104225203.png]]

--- 


### Redis过期策略

#### 惰性删除

>[!tip] 解释
>当一个key已经过期了，redis并不会直接去删除它，而是等用户需要get它时去做一个判断是否已经过期的操作，如果已经过期了就回返nil 并且在这个时候才会真正的把它删除掉。

- **优点**
   1.  对cpu友好，redis不需要专门开一个监视的线程来进行判断是否数据已经过期的动作。

- **缺点**
   1.  消耗内存，如果存在大量已经过期的key并且没有人访问它们，这样它们就只能一直的占用内存，没法被删除。


#### 定期删除

>[!tip] 解释
>redis有一个线程定期巡查的会去数据库中拿部分的数据进行判断是否过期，如果数据已经过期了就把它删除掉，这个巡查时间默认是`10hz` ，且每次清理的时间不超过25ms，这次没清理完就下次清理，尽量减少cpu的占用时间。<mark style="background: #FFB8EBA6;">这个巡查时间的间隔可以在redis.conf中进行调整设置。</mark>


其实定期删除有一下两种模式:

   - `SLOW模式` 是定时去执行清理，执行的频率为10hz（每秒10次） ，每次不超过25ms，能通过redis.conf中的hz配置项去调整执行频率。
   
   - `FAST模式` 的执行频率是不固定的，但是每两次执行的间隔不超过2ms，每次执行的时间不超过1ms。


**总结**： redis本身是两种模式结合使用。

--- 

### Redis淘汰策略

```
当Redis的内存不够使用时再向Redis添加新的key时会触发Redis的数据淘汰策略。
```
- - -

![[Pasted image 20241105134037.png]]


**Redis共有一下8种淘汰策略:**

- `noeviction` ，redis默认淘汰策略，内存不够时不允许新添加数据。

- `volatile-ttl` ，淘汰设置了有效期的数据，有效时间约少，那么被删除的级别越高。

- `allkeys-random` ，对所有的key进行一个随机的删除。

- `volatile-random` ，对所有设置了有效期的数据进行随机的删除。

- `allkeys-lru` ,对所有key使用[LUR算法](Redis的LRU和LFU淘汰算法)进行淘汰删除。

- `volatile-lru` ,对设置了有效期的key使用[LRU算法](Redis的LRU和LFU淘汰算法)进行淘汰删除。

- `allkeys-lfu` ,对所有key使用[LFR算法](Redis的LUR和LFU淘汰算法)进行淘汰删除。

-  `volatile-lfu` ,对设置了有效期的key使用[LFU算法](Redis的LRU和LFU淘汰算法)进行淘汰删除。

--- 



### Redis分布式锁

> [!note] 使用场景（分布式集群）
> 1. 集群下的定时任务（最常用）。
> 2. 抢单之类的。
> 3. 数据做幂等。

实现的逻辑如下：
```shell
#当线程访问资源时拿锁逻辑,下面这行命令时setnx的原子写法
set lock val nx ex 过期时间
#当redis没有lock这个key时才会set，反之拿锁失败
```

![[Pasted image 20241115102810.png]]


#### Redission框架提供一系列分布式锁的解方案

- 原理就是setnx命令，但是redission在底层使用的是lua脚本来确保命令的原子性。

- 看门狗线程监控业务是否执行完成，如果没有完成默认情况下会自动的给锁续期到30秒，它的续期频率为锁的过期时间/3，默认情况下就是10秒执行一次如果发现业务没有完成就自动将key续期到30秒。

- 可重入。为了防止同一个线程中开发人员粗心重复上锁导致死锁的情况发生，redission在上锁时会使用hash结构将锁信息存储在redis。lockKey 线程标识 重入次数。上锁时会先根据判断是否为同一个线程，如果是的话会将冲入次数+1 ，解锁也是同理-1，只有重入次数减为0时才会解锁删key。


上锁存储结构如下图：
![[Pasted image 20241115120540.png]]

#### Redission怎么现实分布式锁的主从一致性的

>[!warning] 问题描述
>如果redis采用的主从集群的方式话，当服务A锁时通过Master节点写入锁信息，如果这个时候服务B也上了同一把锁，恰好Master还没有完成对从节点的数据同步，根据redis主从的特性会将一个从节点升级为主节点，那这个时候服务B上锁因为判断redis中是没有这把锁的所以也会上锁成功，这就导致了两个线程、进程持有一把锁的情况发生。

**解决：** redission采用了`redLock` 红锁机制，上锁成功的前提条件是必须有`总节点数量/2+1` 个节点都完成了数据的存储，否则上锁失败。当然redis的架构思想主要是为了保证高可用，如果你的业务对一致性要求较高可以采用另外的一种cp模型的`zookeeper`来替代。


--- 

## Redis集群

### 主从（高并发）

>[!note] 说明
>redis并发能力是有限的，为解决高并发问题可以使用redis的主从同步来加大并发阈值，并实现读写分离。主节点只负责写缓存，同时将数据同步给所有的从节点，从节点只负责读。

**同步过程、全量、增量：**
   1. slave执行`replicaof`命令对主节点发起连接进行数据同步，同时携带`replid、offset`等信息。
   
   2. master节点接受到连接后会根据`replid`去判断是否为第一次同步。如果是第一次同步则回返自己的`replid` 给从节点，从节点接收到`replid`后会将它保存到本地储存。<mark style="background: #FFF3A3A6;">（不是第一次同步到第6步）</mark>

   3. 主节点执行[[#RDB持久化原理|bgsave命令fork子进程生产RDB文件]]并且发送给从节点。

   4. 从节点接受RDB文件后会清空本地数据然后重新挂载主节点发送的RDB文件。

   5. 主节点在进行RDB文件生成时会将这个时间段来自客户端的写命令记录到repl_backlog日志文件中，完成了RDB文件发送后会将repl_backlog文件发送给从节点，从节点接收到文件后执行文件中的命令进行二次同步，减少了主从数据不一致的情况发生。

   6. 不是第一次同步这时就会触发增量同步。主节点首先回复从节点`continue`。然后根据从节点携带的`offset`去repl_backlog中截取偏移量之后的数据，如果文件共有100行，`offset`为50，则主节点会执行`offset`命令发送50 - 100 这个区间段的数据给从节点进行同步，同步完成后从节点会将最新的`offset`值保存到本地。

--- 

### 哨兵(高并发高可用)

>[!note] 说明
>redis哨兵模式不仅解决了高并发问题同时解决了高可用问题。哨兵利用心跳检测的方式监控所有的节点，当哨兵发现主节点没有响应后会根据规则重新的将一个从节点自己升级为主节点。

**哨兵机制：**
   1. [[#哨兵服务状态监控]]。 哨兵会不断的检查主从节点是否是正常工作。
   2. 如果主节点挂了，哨兵会根据[[#哨兵选主规则]]重新将一个replica升级为主节点。
   3. 由于主节点故障重新选主成功后哨兵会通知redis客户端进行master节点的切换，将最新的群集信息推送到客户端。


#### 哨兵服务状态监控

**哨兵基于心跳检测服务状态，每隔一秒中向集群中的所有实例发送一次ping命令**

- 主观下线：当实例未在指定的时间内响应哨兵pang的命令则视为主观下线。
- 客观下线：超过了`quorum`数量的哨兵都认为这个实例下线了就是客观下线，这个值可以在redis.conf中配置，最好要超过哨兵数量的一半。


#### 哨兵选主规则

- 首先判断该从节点于主节点断开时间的长短，越短说明数据同步的完整性越高那么优先级就越高。
- 然后判断redis.conf中设置的`slave-priority`,该值越小优先级越高。
- 如果`slave-proirity`一样的情况会判断从节点存储的`offset`值，该值越大说明数据完成性越高则优先级越高。


--- 

### Redis哨兵脑裂问题

>[!note] 说明
>当主节点因为网络波动等问题导致和哨兵不在一个网络频段。这时哨兵以为主节点挂了，就会立新主，将一个从节点升级为主节点。但是我们的redis客户端同时还是连接着老的主节点，因为原来的主节点并没有挂，就会出现有两个主节点。所以这个时候的写操作还是往老主节点写，如果这时网络回复了，原先的主节点就会变成新主节点的从节点（听起来有点绕），同时会删除本机所有缓存数据且与新的主节点完成一次全量的数据同步，这个情况就会导致一部分数据的丢失形成redis脑裂。

**解决方案（配置redis.conf）：**
- `min-slaves-to-write 1` 表示至少要有一个从节点才能进行数据的写入。


--- 

### Redis分片集群（高并发读写,海量数据存储）

>[!note] 说明
>redis主从解决了高并发读的问题，哨兵解决了高可用的问题。但是如果数据量非常大，且有高并发写的情况下就可以使用redis的分片集群。

**原理：**
- 要想解决高并发写就得设置多个master节点，并且每个master节点都可以设置多个从节点，这样就解决了高并发的读写问题。%

- 同时每个master之间都基于心跳检测服务来确认是否是正常的执行，如果有多个master都主观认为这个master挂了，就会将挂掉master的一个从节点升级为主节点。

- 利用`hash槽` 来确认某个key应该往那个主节点进行写、读的操作。默认分配了16384个`hash槽`。


**分片集群下如何进行读写操作？**

 ```
 首先redis会将设置的hash槽数量平均的分配给每一个主节点，每一个主节点都有一段可以存储的hash数的范围。当进行读写操作时会先拿这个key基于CRC16算法计算出它的hash值，然后判断这个hash值是在哪个主节点的范围就往哪个主节点进行读写操作。
```

--- 

## Redis是单线程为什么还这么快?

- redis纯操作内存，无需对磁盘进行io。
- redis采用的单线程，能避免线程上下文竞争带来的时间损耗，且无需考虑线程安全问题。
- redis采用的是IO多路复用，非阻塞IO的网络模式。

**结论：** redis纯内存操作无需担心性能问题，影响性能的是网络延迟等问题，然而redis采用了IO多路服用的网络模型实现了高效的网络请求性能。

<mark style="background: #FFB8EBA6;">关于什么是IO多路复用，对不起我不是很了解，也有精力去了解，以后有时间再说...</mark>
